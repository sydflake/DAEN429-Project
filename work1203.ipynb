{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sydflake/DAEN429-Project/blob/main/work1203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a962959",
      "metadata": {
        "id": "9a962959"
      },
      "source": [
        "# DAEN 429 Final Project\n",
        "Sydney Flake, Maddie Bird, Jade Winebright"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71f3ce65",
      "metadata": {
        "id": "71f3ce65"
      },
      "source": [
        "## Phase 0: Setup + ResNet 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c049e893",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c049e893",
        "outputId": "13930883-9bec-4c17-bc0c-d457c65f2766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use GPU if available\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# For reproducibility\n",
        "SEED = 429\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Turn on cuDNN benchmark for speed (optional)\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1f121953",
      "metadata": {
        "id": "1f121953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17b88a1-c8a7-4b60-8638-a015529a02e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'asl-alphabet' dataset.\n",
            "Path to dataset files: /kaggle/input/asl-alphabet\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "00fcb963",
      "metadata": {
        "id": "00fcb963",
        "outputId": "16c274b4-2e6c-4dec-d7f2-cdb83e33c0a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 87000\n",
            "Number of classes: 29\n",
            "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'] ...\n"
          ]
        }
      ],
      "source": [
        "# Load the full ASL dataset\n",
        "\n",
        "#local\n",
        "#DATA_ROOT = \"/Users/flake/Documents/DAEN429/project/Datasets/asl_alphabet_train/asl_alphabet_train\"\n",
        "\n",
        "#gdrive\n",
        "DATA_ROOT = os.path.join(path, \"asl_alphabet_train\", \"asl_alphabet_train\")\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=DATA_ROOT, transform=None)\n",
        "print(\"Total images:\", len(full_dataset))\n",
        "print(\"Number of classes:\", len(full_dataset.classes))\n",
        "print(\"Classes:\", full_dataset.classes[:10], \"...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4a3682f3",
      "metadata": {
        "id": "4a3682f3",
        "outputId": "63a157e4-10aa-49ba-d98d-5451faa3d9e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size (indices): 69600\n",
            "Val size (indices): 17400\n"
          ]
        }
      ],
      "source": [
        "# ---- Stratified 80/20 split with seed = 429 ----\n",
        "indices = np.arange(len(full_dataset))\n",
        "labels = np.array(full_dataset.targets)  # class indices 0..(num_classes-1)\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    indices, test_size=0.2, stratify=labels, random_state=429\n",
        ")\n",
        "\n",
        "print(\"Train size (indices):\", len(train_idx))\n",
        "print(\"Val size (indices):\", len(val_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "123ea263",
      "metadata": {
        "id": "123ea263"
      },
      "outputs": [],
      "source": [
        "# Define data transformations for training and validation sets\n",
        "\n",
        "# ImageNet normalization (what ResNet-18 expects)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    #transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    #transforms.RandomHorizontalFlip(),\n",
        "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "\"\"\"val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "536c8cfd",
      "metadata": {
        "id": "536c8cfd",
        "outputId": "864bba4c-8ec6-46d4-a8b1-4add4e9b7cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Custom Subset class to apply different transforms per split\\n\\n# ---- Subset wrapper that allows per-split transforms ----\\nclass SubsetWithTransform(Subset):\\n    def __init__(self, dataset, indices, transform=None):\\n        super().__init__(dataset, indices)\\n        self.transform = transform\\n\\n    def __getitem__(self, idx):\\n        real_idx = self.indices[idx]\\n        img, label = self.dataset[real_idx]  # base dataset has transform=None\\n        if self.transform is not None:\\n            img = self.transform(img)\\n        return img, label\\n\\n# Make sure base dataset doesn’t apply transforms itself\\nfull_dataset.transform = None\\n\\ntrain_dataset = SubsetWithTransform(full_dataset, train_idx, transform=train_transform)\\nval_dataset   = SubsetWithTransform(full_dataset, val_idx,   transform=val_transform)\\n\\nprint(\"Train size:\", len(train_dataset))\\nprint(\"Val size:\", len(val_dataset))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\"\"\"# Custom Subset class to apply different transforms per split\n",
        "\n",
        "# ---- Subset wrapper that allows per-split transforms ----\n",
        "class SubsetWithTransform(Subset):\n",
        "    def __init__(self, dataset, indices, transform=None):\n",
        "        super().__init__(dataset, indices)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = self.indices[idx]\n",
        "        img, label = self.dataset[real_idx]  # base dataset has transform=None\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Make sure base dataset doesn’t apply transforms itself\n",
        "full_dataset.transform = None\n",
        "\n",
        "train_dataset = SubsetWithTransform(full_dataset, train_idx, transform=train_transform)\n",
        "val_dataset   = SubsetWithTransform(full_dataset, val_idx,   transform=val_transform)\n",
        "\n",
        "print(\"Train size:\", len(train_dataset))\n",
        "print(\"Val size:\", len(val_dataset))\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4b735c3b",
      "metadata": {
        "id": "4b735c3b",
        "outputId": "3cdbe2f1-fb7a-4972-d94c-9b047838a66d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final train size: 69600\n",
            "Final val size: 17400\n",
            "Train sample type: <class 'torch.Tensor'>\n",
            "Train sample shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# Create base dataset each with its own transforms\n",
        "# Dataset for training: same files, but with train_transform\n",
        "train_full = datasets.ImageFolder(root=DATA_ROOT, transform=train_transform)\n",
        "\n",
        "# Dataset for validation: same files, but with val_transform\n",
        "val_full   = datasets.ImageFolder(root=DATA_ROOT, transform=val_transform)\n",
        "\n",
        "# Now apply the *same indices* to each\n",
        "train_dataset = Subset(train_full, train_idx)\n",
        "val_dataset   = Subset(val_full,   val_idx)\n",
        "\n",
        "print(\"Final train size:\", len(train_dataset))\n",
        "print(\"Final val size:\", len(val_dataset))\n",
        "\n",
        "# Sanity check: the first sample should be a tensor\n",
        "x0, y0 = train_dataset[0]\n",
        "print(\"Train sample type:\", type(x0))     # should be <class 'torch.Tensor'>\n",
        "print(\"Train sample shape:\", x0.shape)    # e.g. torch.Size([3, 224, 224])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9198e060",
      "metadata": {
        "id": "9198e060",
        "outputId": "f67d3840-3f27-448c-b07e-ba86579173e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num train batches: 1088\n",
            "Num val batches: 272\n"
          ]
        }
      ],
      "source": [
        "# ---- DataLoaders ----\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "pin = True if device.type == \"cuda\" else False\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,    # 0 if local, 2 if gdrive\n",
        "    pin_memory=pin,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,    # same here\n",
        "    pin_memory=pin,\n",
        ")\n",
        "\n",
        "print(\"Num train batches:\", len(train_loader))\n",
        "print(\"Num val batches:\", len(val_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3118b64f",
      "metadata": {
        "id": "3118b64f"
      },
      "source": [
        "## Phase 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ddd4b31d",
      "metadata": {
        "id": "ddd4b31d",
        "outputId": "796be650-3687-46ca-c743-8e5601b34c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 29\n",
            "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(full_dataset.classes)\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Classes:\", full_dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0182548d",
      "metadata": {
        "id": "0182548d"
      },
      "outputs": [],
      "source": [
        "def create_resnet18_model(num_classes, pretrained=True):\n",
        "    \"\"\"\n",
        "    Create a ResNet-18 model with a custom classifier head for ASL classes.\n",
        "    If pretrained=True → use ImageNet weights (for T-A, T-B, T-C).\n",
        "    If pretrained=False → random init (for S-A).\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
        "        model = resnet18(weights=weights)\n",
        "        print(\"Loaded ResNet-18 with ImageNet pretrained weights.\")\n",
        "    else:\n",
        "        model = resnet18(weights=None)\n",
        "        print(\"Loaded ResNet-18 from scratch (no pretrained weights).\")\n",
        "\n",
        "    # Replace the final fully connected layer\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f675676b",
      "metadata": {
        "id": "f675676b"
      },
      "outputs": [],
      "source": [
        "# Freezing/unfreezing policies\n",
        "def apply_freezing_policy(model, policy):\n",
        "    \"\"\"\n",
        "    policy: one of {\"T-A\", \"T-B\", \"T-C\", \"S-A\"}\n",
        "\n",
        "    T-A: Head-only, freeze all backbone, train fc.\n",
        "    T-B: Freeze stem + layer1 + layer2 + layer3; train layer4 + fc.\n",
        "    T-C: Freeze stem + layer1 + layer2; train layer3 + layer4 + fc.\n",
        "    S-A: From scratch, train all layers (no freezing).\n",
        "    \"\"\"\n",
        "    # First, freeze everything\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    if policy == \"T-A\":\n",
        "        # Train only the classifier head\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif policy == \"T-B\":\n",
        "        # Train layer4 and head\n",
        "        for param in model.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif policy == \"T-C\":\n",
        "        # Train layer3, layer4, and head\n",
        "        for param in model.layer3.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif policy == \"S-A\":\n",
        "        # From scratch: train everything\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown policy: {policy}\")\n",
        "\n",
        "    \"\"\"# Optional: set BatchNorm layers in frozen parts to eval mode\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            # if all params in this BN are frozen, keep it in eval\n",
        "            if not any(p.requires_grad for p in m.parameters()):\n",
        "                m.eval()\"\"\"\n",
        "\n",
        "    # Print a quick summary\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Policy {policy}: trainable params = {trainable_params}/{total_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aed0cda1",
      "metadata": {
        "id": "aed0cda1"
      },
      "source": [
        "Reusable code for the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "384c8efe",
      "metadata": {
        "id": "384c8efe"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def get_optimizer(model, lr=1e-3, weight_decay=1e-4, optimizer_name=\"Adam\"):\n",
        "    \"\"\"\n",
        "    Returns an optimizer over ONLY trainable parameters.\n",
        "    \"\"\"\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    if optimizer_name == \"Adam\":\n",
        "        optimizer = optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == \"SGD\":\n",
        "        optimizer = optim.SGD(params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
        "\n",
        "    return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e32f2888",
      "metadata": {
        "id": "e32f2888"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.append(preds.detach().cpu())\n",
        "        all_targets.append(labels.detach().cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
        "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bd6d7cba",
      "metadata": {
        "id": "bd6d7cba"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.append(preds.detach().cpu())\n",
        "            all_targets.append(labels.detach().cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
        "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1, all_preds, all_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "af9940d0",
      "metadata": {
        "id": "af9940d0"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    num_epochs=10,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    optimizer_name=\"Adam\",\n",
        "    experiment_name=\"exp\"\n",
        "):\n",
        "    optimizer = get_optimizer(model, lr=lr, weight_decay=weight_decay, optimizer_name=optimizer_name)\n",
        "\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"train_f1\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "        \"val_f1\": [],\n",
        "    }\n",
        "\n",
        "    best_val_f1 = -1.0\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, device)\n",
        "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, device)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"train_f1\"].append(train_f1)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_f1\"].append(val_f1)\n",
        "\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_state = {\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"epoch\": epoch,\n",
        "                \"val_f1\": val_f1,\n",
        "                \"val_acc\": val_acc,\n",
        "            }\n",
        "\n",
        "        print(\n",
        "            f\"[{experiment_name}] Epoch {epoch:02d}/{num_epochs:02d} | \"\n",
        "            f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "    print(f\"\\n[{experiment_name}] Best val macro-F1: {best_val_f1:.4f}\")\n",
        "    return model, history, best_state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec448c2",
      "metadata": {
        "id": "2ec448c2"
      },
      "source": [
        "### T-A: Head Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1ca51348",
      "metadata": {
        "id": "1ca51348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "1b478bb4-c71c-4638-9521-03bf9372d4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ResNet-18 with ImageNet pretrained weights.\n",
            "Policy T-A: trainable params = 14877/11191389\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2155484603.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_TA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_TA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model_TA, history_TA, best_TA = train_model(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_TA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-398918663.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, device, num_epochs, lr, weight_decay, optimizer_name, experiment_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-668086559.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3522\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ===== T-A: Head-only finetuning =====\n",
        "model_TA = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
        "apply_freezing_policy(model_TA, policy=\"T-A\")\n",
        "model_TA = model_TA.to(device)\n",
        "\n",
        "model_TA, history_TA, best_TA = train_model(\n",
        "    model_TA,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    num_epochs=3,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    optimizer_name=\"Adam\",\n",
        "    experiment_name=\"T-A_head_only\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32330d76",
      "metadata": {
        "id": "32330d76"
      },
      "outputs": [],
      "source": [
        "# For personal storage\n",
        "#os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "#ta_ckpt_path = \"/checkpoints/resnet18_TA_best.pth\"\n",
        "#torch.save(best_TA, ta_ckpt_path)\n",
        "#print(\"Saved best T-A checkpoint to:\", ta_ckpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40ec155",
      "metadata": {
        "id": "e40ec155"
      },
      "outputs": [],
      "source": [
        "# For Google Drive storage\n",
        "# 5) Save the best T-A checkpoint\n",
        "os.makedirs(\"/content/drive/MyDrive/DAEN429/checkpoints\", exist_ok=True)\n",
        "\n",
        "ta_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TA_best.pth\"\n",
        "torch.save(best_TA, ta_ckpt_path)\n",
        "print(\"Saved best T-A checkpoint to:\", ta_ckpt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07873237",
      "metadata": {
        "id": "07873237"
      },
      "source": [
        "### T-B: Last Block Unfrozen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "954de024",
      "metadata": {
        "id": "954de024"
      },
      "outputs": [],
      "source": [
        "# ===== T-B: Last block (layer4) + head finetuning =====\n",
        "\n",
        "model_TB = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
        "apply_freezing_policy(model_TB, policy=\"T-B\")\n",
        "model_TB = model_TB.to(device)\n",
        "\n",
        "model_TB, history_TB, best_TB = train_model(\n",
        "    model_TB,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    num_epochs=10,          # adjust if you want longer/shorter\n",
        "    lr=1e-4,                # often a bit smaller when unfreezing more layers\n",
        "    weight_decay=1e-4,\n",
        "    optimizer_name=\"Adam\",\n",
        "    experiment_name=\"T-B_last_block_plus_head\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c890dc0",
      "metadata": {
        "id": "9c890dc0"
      },
      "outputs": [],
      "source": [
        "# For personal storage\n",
        "#os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "#tb_ckpt_path = \"/checkpoints/resnet18_TB_best.pth\"\n",
        "#torch.save(best_TB, tb_ckpt_path)\n",
        "#print(\"Saved best T-B checkpoint to:\", tb_ckpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db37c434",
      "metadata": {
        "id": "db37c434"
      },
      "outputs": [],
      "source": [
        "# For Google Drive storage\n",
        "# Save the best T-B model checkpoint\n",
        "tb_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TB_best.pth\"\n",
        "torch.save(best_TB, tb_ckpt_path)\n",
        "print(\"Saved best T-B checkpoint to:\", tb_ckpt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b393e559",
      "metadata": {
        "id": "b393e559"
      },
      "source": [
        "### T-C: Progressive Unfreezing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57a3f23",
      "metadata": {
        "id": "e57a3f23"
      },
      "outputs": [],
      "source": [
        "# ===== T-C: Progressive unfreezing =====\n",
        "\n",
        "# 1) Recreate same model architecture used in T-B\n",
        "model_TC = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
        "\n",
        "# 2) Load best T-B checkpoint\n",
        "tb_checkpoint = torch.load(\"checkpoints/resnet18_TB_best.pth\", map_location=device)\n",
        "model_TC.load_state_dict(tb_checkpoint[\"model_state_dict\"])\n",
        "\n",
        "print(\n",
        "    f\"Loaded T-B checkpoint from epoch {tb_checkpoint['epoch']} \"\n",
        "    f\"with val F1 = {tb_checkpoint['val_f1']:.4f}\"\n",
        ")\n",
        "\n",
        "# 3) Apply T-C freezing policy (layer3 + layer4 + fc trainable)\n",
        "apply_freezing_policy(model_TC, policy=\"T-C\")\n",
        "\n",
        "# 4) Move to GPU/CPU\n",
        "model_TC = model_TC.to(device)\n",
        "\n",
        "# 5) Train with a lower LR (to avoid destroying T-B’s good weights)\n",
        "model_TC, history_TC, best_TC = train_model(\n",
        "    model_TC,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    num_epochs=10,                # adjust as needed\n",
        "    lr=5e-5,                      # smaller LR recommended\n",
        "    weight_decay=1e-4,\n",
        "    optimizer_name=\"Adam\",\n",
        "    experiment_name=\"T-C_progressive_unfreeze\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d820aedb",
      "metadata": {
        "id": "d820aedb"
      },
      "outputs": [],
      "source": [
        "# For personal storage\n",
        "#os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "#tc_ckpt_path = \"/checkpoints/resnet18_TC_best.pth\"\n",
        "#torch.save(best_TC, tc_ckpt_path)\n",
        "#print(\"Saved best T-C checkpoint to:\", tc_ckpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a73331",
      "metadata": {
        "id": "e4a73331"
      },
      "outputs": [],
      "source": [
        "# For Google Drive storage\n",
        "# 6) Save best checkpoint\n",
        "tc_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TC_best.pth\"\n",
        "torch.save(best_TC, tc_ckpt_path)\n",
        "print(\"Saved best T-C checkpoint to:\", tc_ckpt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbbcd277",
      "metadata": {
        "id": "dbbcd277"
      },
      "source": [
        "### S-A: Train From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6710094b",
      "metadata": {
        "id": "6710094b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}