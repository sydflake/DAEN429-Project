{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 29550,
          "sourceType": "datasetVersion",
          "datasetId": 23079,
          "isSourceIdPinned": false
        },
        {
          "sourceId": 14002562,
          "sourceType": "datasetVersion",
          "datasetId": 8921815
        },
        {
          "sourceId": 14002601,
          "sourceType": "datasetVersion",
          "datasetId": 8921843
        },
        {
          "sourceId": 14035534,
          "sourceType": "datasetVersion",
          "datasetId": 8937677
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "_YsZi3NlIQTE"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "grassknoted_asl_alphabet_path = kagglehub.dataset_download('grassknoted/asl-alphabet')\n",
        "\n",
        "jadecw_try_custom2_path = kagglehub.dataset_download('jadecw/try-custom2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "gr8le1rOIQTG"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset, Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:15:42.848353Z",
          "iopub.execute_input": "2025-12-06T20:15:42.848585Z",
          "iopub.status.idle": "2025-12-06T20:15:51.980457Z",
          "shell.execute_reply.started": "2025-12-06T20:15:42.848563Z",
          "shell.execute_reply": "2025-12-06T20:15:51.979881Z"
        },
        "id": "lZPI-f0iIQTH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 0: SETUP & REPRODUCIBILITY\n",
        "# ============================================================================\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\\n\")\n",
        "\n",
        "SEED = 429\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:15:51.981656Z",
          "iopub.execute_input": "2025-12-06T20:15:51.982042Z",
          "iopub.status.idle": "2025-12-06T20:15:52.076339Z",
          "shell.execute_reply.started": "2025-12-06T20:15:51.982023Z",
          "shell.execute_reply": "2025-12-06T20:15:52.075303Z"
        },
        "id": "E7471syWIQTH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== DATASET PATHS =====\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "print(f\"Dataset downloaded to: {path}\\n\")\n",
        "\n",
        "DATA_ROOT_TRAIN = os.path.join(path, \"asl_alphabet_train\", \"asl_alphabet_train\")\n",
        "DATA_ROOT_TEST = os.path.join(path, \"asl_alphabet_test\", \"asl_alphabet_test\")\n",
        "\n",
        "print(f\"Training path: {DATA_ROOT_TRAIN}\")\n",
        "print(f\"Test path: {DATA_ROOT_TEST}\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:15:52.077189Z",
          "iopub.execute_input": "2025-12-06T20:15:52.077399Z",
          "iopub.status.idle": "2025-12-06T20:15:52.318249Z",
          "shell.execute_reply.started": "2025-12-06T20:15:52.077381Z",
          "shell.execute_reply": "2025-12-06T20:15:52.317663Z"
        },
        "id": "lUenhPEwIQTI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 1: FLAT TEST DATASET CLASS\n",
        "# ============================================================================\n",
        "\n",
        "class FlatTestDataset(Dataset):\n",
        "    \"\"\"Handles test set with one image per class.\"\"\"\n",
        "\n",
        "    def __init__(self, image_dir, class_names, transform=None,\n",
        "                 valid_extensions=('.jpg', '.jpeg', '.png')):\n",
        "        self.image_dir = image_dir\n",
        "        self.class_names = class_names\n",
        "        self.transform = transform\n",
        "        self.valid_extensions = valid_extensions\n",
        "\n",
        "        self.image_files = []\n",
        "        for filename in sorted(os.listdir(image_dir)):\n",
        "            if any(filename.lower().endswith(ext) for ext in valid_extensions):\n",
        "                self.image_files.append(filename)\n",
        "\n",
        "        if len(self.image_files) == 0:\n",
        "            raise FileNotFoundError(f\"No images found in {image_dir}\")\n",
        "\n",
        "        print(f\"Found {len(self.image_files)} test images\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, filename)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "            raise\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        true_label = self.get_class_from_filename(filename)\n",
        "        return img, filename, true_label\n",
        "\n",
        "    def get_class_from_filename(self, filename):\n",
        "        \"\"\"Extract class label from filename.\"\"\"\n",
        "        if filename.lower().startswith(\"nothing\"):\n",
        "            return \"nothing\"\n",
        "        elif filename.lower().startswith(\"space\"):\n",
        "            return \"space\"\n",
        "        else:\n",
        "            return filename[0].upper()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:15:52.318922Z",
          "iopub.execute_input": "2025-12-06T20:15:52.319149Z",
          "iopub.status.idle": "2025-12-06T20:15:52.326209Z",
          "shell.execute_reply.started": "2025-12-06T20:15:52.319132Z",
          "shell.execute_reply": "2025-12-06T20:15:52.325516Z"
        },
        "id": "aq2aE3KOIQTI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 2: DATA LOADING WITH ADVANCED AUGMENTATION\n",
        "# ============================================================================\n",
        "\n",
        "# ===== LOAD TRAINING SET =====\n",
        "full_train_dataset = datasets.ImageFolder(root=DATA_ROOT_TRAIN, transform=None)\n",
        "num_classes = len(full_train_dataset.classes)\n",
        "\n",
        "print(f\"✓ Training set loaded: {len(full_train_dataset)} images\")\n",
        "print(f\"✓ Number of classes: {num_classes}\")\n",
        "print(f\"✓ Classes: {full_train_dataset.classes}\\n\")\n",
        "\n",
        "# ===== CREATE 80/20 STRATIFIED SPLIT (SEED=429) =====\n",
        "indices = np.arange(len(full_train_dataset))\n",
        "labels = np.array(full_train_dataset.targets)\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    indices, test_size=0.2, stratify=labels, random_state=429\n",
        ")\n",
        "\n",
        "print(f\"✓ Train/Val split created:\")\n",
        "print(f\"  Train: {len(train_idx)} images\")\n",
        "print(f\"  Val: {len(val_idx)} images\\n\")\n",
        "\n",
        "# ===== DEFINE TRANSFORMS WITH DATA AUGMENTATION =====\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "# TRAINING: augmentation to handle real-world variations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "\n",
        "    # Geometric augmentations\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "\n",
        "    # Color/brightness augmentations\n",
        "    transforms.ColorJitter(\n",
        "        brightness=0.3,\n",
        "        contrast=0.3,\n",
        "        saturation=0.2,\n",
        "        hue=0.1\n",
        "    ),\n",
        "\n",
        "    # Blur\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),\n",
        "\n",
        "    # Final conversions\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# VALIDATION & TEST: No augmentation\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA AUGMENTATION STRATEGY\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "Training Set Augmentations:\n",
        "  1. Geometric:\n",
        "     - Random horizontal flip (50%)\n",
        "     - Random rotation (±15°)\n",
        "     - Random translation (±10%)\n",
        "\n",
        "  2. Color/Brightness:\n",
        "     - Brightness (±30%)\n",
        "     - Contrast (±30%)\n",
        "     - Saturation (±20%)\n",
        "     - Hue (±10%)\n",
        "\n",
        "  3. Blur: Gaussian blur for camera simulation\n",
        "\n",
        "Validation & Test: No augmentation (consistent evaluation)\n",
        "\"\"\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "# ===== CREATE DATASETS WITH TRANSFORMS =====\n",
        "train_full = datasets.ImageFolder(root=DATA_ROOT_TRAIN, transform=train_transform)\n",
        "val_full = datasets.ImageFolder(root=DATA_ROOT_TRAIN, transform=val_test_transform)\n",
        "\n",
        "train_dataset = Subset(train_full, train_idx)\n",
        "val_dataset = Subset(val_full, val_idx)\n",
        "\n",
        "# ===== LOAD TEST SET =====\n",
        "test_dataset_original = FlatTestDataset(\n",
        "    DATA_ROOT_TEST, full_train_dataset.classes,\n",
        "    transform=val_test_transform\n",
        ")\n",
        "print(f\"✓ Test set loaded: {len(test_dataset_original)} images\\n\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:15:52.327945Z",
          "iopub.execute_input": "2025-12-06T20:15:52.328239Z",
          "iopub.status.idle": "2025-12-06T20:18:34.939983Z",
          "shell.execute_reply.started": "2025-12-06T20:15:52.328223Z",
          "shell.execute_reply": "2025-12-06T20:18:34.939326Z"
        },
        "id": "HAKApJo_IQTI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 3: HYPERPARAMETER CONFIGURATION FOR ALL POLICIES\n",
        "# ============================================================================\n",
        "\n",
        "HYPERPARAMS = {\n",
        "    \"T-A\": {\n",
        "        \"num_epochs\": 5,\n",
        "        \"batch_size\": 128,\n",
        "        \"lr\": 1e-2,\n",
        "        \"weight_decay\": 1e-5,\n",
        "        \"optimizer\": \"Adam\",\n",
        "    },\n",
        "    \"T-B\": {\n",
        "        \"num_epochs\": 5,\n",
        "        \"batch_size\": 64,\n",
        "        \"lr\": 5e-4,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"optimizer\": \"Adam\",\n",
        "    },\n",
        "    \"T-C\": {\n",
        "        \"num_epochs\": 5,\n",
        "        \"batch_size\": 64,\n",
        "        \"lr\": 1e-4,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"optimizer\": \"Adam\",\n",
        "    },\n",
        "    \"S-A\": {\n",
        "        \"num_epochs\": 5,\n",
        "        \"batch_size\": 32,\n",
        "        \"lr\": 1e-3,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"optimizer\": \"SGD\",\n",
        "    },\n",
        "}\n",
        "\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"HYPERPARAMETER CONFIGURATION\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "for policy, params in HYPERPARAMS.items():\n",
        "    print(f\"{policy}:\")\n",
        "    for key, value in params.items():\n",
        "        print(f\"  {key:15s}: {value}\")\n",
        "    print()\n",
        "\n",
        "# ===== HELPER: Create DataLoaders with Specific Batch Size =====\n",
        "def create_dataloaders(batch_size, train_idx, val_idx):\n",
        "    \"\"\"Create dataloaders with specified batch size.\"\"\"\n",
        "    train_full_local = datasets.ImageFolder(root=DATA_ROOT_TRAIN, transform=train_transform)\n",
        "    val_full_local = datasets.ImageFolder(root=DATA_ROOT_TRAIN, transform=val_test_transform)\n",
        "\n",
        "    train_dataset_local = Subset(train_full_local, train_idx)\n",
        "    val_dataset_local = Subset(val_full_local, val_idx)\n",
        "\n",
        "    pin = True if device.type == \"cuda\" else False\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset_local, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=2, pin_memory=pin\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset_local, batch_size=batch_size, shuffle=False,\n",
        "        num_workers=2, pin_memory=pin\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:18:34.940681Z",
          "iopub.execute_input": "2025-12-06T20:18:34.94088Z",
          "iopub.status.idle": "2025-12-06T20:18:34.949257Z",
          "shell.execute_reply.started": "2025-12-06T20:18:34.940863Z",
          "shell.execute_reply": "2025-12-06T20:18:34.948516Z"
        },
        "id": "C5d0G_FUIQTI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 4: MODEL CREATION & FREEZING POLICIES\n",
        "# ============================================================================\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def create_resnet18(num_classes, pretrained=True):\n",
        "    \"\"\"Create ResNet-18 with custom head.\"\"\"\n",
        "    if pretrained:\n",
        "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
        "        model = resnet18(weights=weights)\n",
        "        print(f\"✓ Created ResNet-18 with ImageNet weights\")\n",
        "    else:\n",
        "        model = resnet18(weights=None)\n",
        "        print(f\"✓ Created ResNet-18 from scratch\")\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def apply_policy(model, policy):\n",
        "    \"\"\"Apply freezing policy.\"\"\"\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    if policy == \"T-A\":\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif policy == \"T-B\":\n",
        "        for param in model.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif policy == \"T-C\":\n",
        "        for param in model.layer3.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif policy == \"S-A\":\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Policy {policy}: {trainable:,} / {total:,} parameters trainable\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:18:34.950086Z",
          "iopub.execute_input": "2025-12-06T20:18:34.950326Z",
          "iopub.status.idle": "2025-12-06T20:18:34.966294Z",
          "shell.execute_reply.started": "2025-12-06T20:18:34.950305Z",
          "shell.execute_reply": "2025-12-06T20:18:34.96557Z"
        },
        "id": "Y0sfjyveIQTJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 5: TRAINING FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def get_optimizer(model, lr=1e-3, weight_decay=1e-4, optimizer_name=\"Adam\"):\n",
        "    \"\"\"Get optimizer for trainable parameters.\"\"\"\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    if optimizer_name == \"Adam\":\n",
        "        optimizer = optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == \"SGD\":\n",
        "        optimizer = optim.SGD(params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, device):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.append(preds.detach().cpu())\n",
        "        all_targets.append(labels.detach().cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
        "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    \"\"\"Evaluate on validation/test set.\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            images = batch[0].to(device)\n",
        "\n",
        "            if len(batch) == 2:\n",
        "                labels = batch[1].to(device)\n",
        "            else:\n",
        "                labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.append(preds.detach().cpu())\n",
        "            all_targets.append(labels.detach().cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
        "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_f1, all_preds, all_targets\n",
        "\n",
        "def train_model(model, train_loader, val_loader, device, num_epochs=10,\n",
        "                lr=1e-3, weight_decay=1e-4, optimizer_name=\"Adam\",\n",
        "                experiment_name=\"exp\"):\n",
        "    \"\"\"Train model with best checkpoint tracking.\"\"\"\n",
        "    optimizer = get_optimizer(model, lr=lr, weight_decay=weight_decay,\n",
        "                             optimizer_name=optimizer_name)\n",
        "\n",
        "    history = {\n",
        "        \"train_loss\": [], \"train_acc\": [], \"train_f1\": [],\n",
        "        \"val_loss\": [], \"val_acc\": [], \"val_f1\": [],\n",
        "    }\n",
        "\n",
        "    best_val_f1 = -1.0\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train_loss, train_acc, train_f1 = train_one_epoch(\n",
        "            model, train_loader, optimizer, device\n",
        "        )\n",
        "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, device)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"train_f1\"].append(train_f1)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_f1\"].append(val_f1)\n",
        "\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_state = {\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"epoch\": epoch,\n",
        "                \"val_f1\": val_f1,\n",
        "                \"val_acc\": val_acc,\n",
        "            }\n",
        "\n",
        "        print(\n",
        "            f\"[{experiment_name}] Epoch {epoch:02d}/{num_epochs:02d} | \"\n",
        "            f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "    print(f\"\\n[{experiment_name}] Best val macro-F1: {best_val_f1:.4f}\\n\")\n",
        "    return model, history, best_state\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:18:34.967075Z",
          "iopub.execute_input": "2025-12-06T20:18:34.967334Z",
          "iopub.status.idle": "2025-12-06T20:18:34.983567Z",
          "shell.execute_reply.started": "2025-12-06T20:18:34.96731Z",
          "shell.execute_reply": "2025-12-06T20:18:34.983002Z"
        },
        "id": "3R3qG7P6IQTJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 6: TRAIN ALL FOUR MODELS WITH OPTIMIZED HYPERPARAMETERS\n",
        "# ============================================================================\n",
        "\n",
        "results_summary = {}\n",
        "all_histories = {}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:18:34.984285Z",
          "iopub.execute_input": "2025-12-06T20:18:34.984546Z",
          "iopub.status.idle": "2025-12-06T20:18:34.996098Z",
          "shell.execute_reply.started": "2025-12-06T20:18:34.984522Z",
          "shell.execute_reply": "2025-12-06T20:18:34.995451Z"
        },
        "id": "O_nqbFThIQTJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== T-A: HEAD ONLY =====\n",
        "print(\"=\" * 80)\n",
        "print(\"TRAINING: T-A (Head Only)\")\n",
        "print(\"=\" * 80)\n",
        "print_params = HYPERPARAMS[\"T-A\"]\n",
        "print(f\"LR={print_params['lr']}, BatchSize={print_params['batch_size']}, \"\n",
        "      f\"Optimizer={print_params['optimizer']}, Epochs={print_params['num_epochs']}\\n\")\n",
        "\n",
        "train_loader_TA, val_loader_TA = create_dataloaders(\n",
        "    HYPERPARAMS[\"T-A\"][\"batch_size\"], train_idx, val_idx\n",
        ")\n",
        "\n",
        "model_TA = create_resnet18(num_classes=num_classes, pretrained=True)\n",
        "apply_policy(model_TA, \"T-A\")\n",
        "model_TA = model_TA.to(device)\n",
        "\n",
        "model_TA, history_TA, best_TA = train_model(\n",
        "    model_TA, train_loader_TA, val_loader_TA, device,\n",
        "    num_epochs=HYPERPARAMS[\"T-A\"][\"num_epochs\"],\n",
        "    lr=HYPERPARAMS[\"T-A\"][\"lr\"],\n",
        "    weight_decay=HYPERPARAMS[\"T-A\"][\"weight_decay\"],\n",
        "    optimizer_name=HYPERPARAMS[\"T-A\"][\"optimizer\"],\n",
        "    experiment_name=\"T-A\"\n",
        ")\n",
        "\n",
        "torch.save(best_TA, \"checkpoints/resnet18_T-A_best.pth\")\n",
        "results_summary[\"T-A\"] = best_TA\n",
        "all_histories[\"T-A\"] = history_TA\n",
        "print(\"✓ Saved T-A checkpoint\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:18:34.996861Z",
          "iopub.execute_input": "2025-12-06T20:18:34.997391Z",
          "iopub.status.idle": "2025-12-06T20:45:34.872349Z",
          "shell.execute_reply.started": "2025-12-06T20:18:34.997375Z",
          "shell.execute_reply": "2025-12-06T20:45:34.871335Z"
        },
        "id": "DD1OCXX_IQTK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== T-B: LAST BLOCK + HEAD =====\n",
        "print(\"=\" * 80)\n",
        "print(\"TRAINING: T-B (Last Block + Head)\")\n",
        "print(\"=\" * 80)\n",
        "print_params = HYPERPARAMS[\"T-B\"]\n",
        "print(f\"LR={print_params['lr']}, BatchSize={print_params['batch_size']}, \"\n",
        "      f\"Optimizer={print_params['optimizer']}, Epochs={print_params['num_epochs']}\\n\")\n",
        "\n",
        "train_loader_TB, val_loader_TB = create_dataloaders(\n",
        "    HYPERPARAMS[\"T-B\"][\"batch_size\"], train_idx, val_idx\n",
        ")\n",
        "\n",
        "model_TB = create_resnet18(num_classes=num_classes, pretrained=True)\n",
        "apply_policy(model_TB, \"T-B\")\n",
        "model_TB = model_TB.to(device)\n",
        "\n",
        "model_TB, history_TB, best_TB = train_model(\n",
        "    model_TB, train_loader_TB, val_loader_TB, device,\n",
        "    num_epochs=HYPERPARAMS[\"T-B\"][\"num_epochs\"],\n",
        "    lr=HYPERPARAMS[\"T-B\"][\"lr\"],\n",
        "    weight_decay=HYPERPARAMS[\"T-B\"][\"weight_decay\"],\n",
        "    optimizer_name=HYPERPARAMS[\"T-B\"][\"optimizer\"],\n",
        "    experiment_name=\"T-B\"\n",
        ")\n",
        "\n",
        "torch.save(best_TB, \"checkpoints/resnet18_T-B_best.pth\")\n",
        "results_summary[\"T-B\"] = best_TB\n",
        "all_histories[\"T-B\"] = history_TB\n",
        "print(\"✓ Saved T-B checkpoint\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T20:45:34.873559Z",
          "iopub.execute_input": "2025-12-06T20:45:34.874248Z",
          "iopub.status.idle": "2025-12-06T21:09:35.067598Z",
          "shell.execute_reply.started": "2025-12-06T20:45:34.874221Z",
          "shell.execute_reply": "2025-12-06T21:09:35.066773Z"
        },
        "id": "q6ziwBcHIQTK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== T-C: PROGRESSIVE UNFREEZING =====\n",
        "print(\"=\" * 80)\n",
        "print(\"TRAINING: T-C (Progressive Unfreezing)\")\n",
        "print(\"=\" * 80)\n",
        "print_params = HYPERPARAMS[\"T-C\"]\n",
        "print(f\"LR={print_params['lr']}, BatchSize={print_params['batch_size']}, \"\n",
        "      f\"Optimizer={print_params['optimizer']}, Epochs={print_params['num_epochs']}\\n\")\n",
        "\n",
        "train_loader_TC, val_loader_TC = create_dataloaders(\n",
        "    HYPERPARAMS[\"T-C\"][\"batch_size\"], train_idx, val_idx\n",
        ")\n",
        "\n",
        "model_TC = create_resnet18(num_classes=num_classes, pretrained=True)\n",
        "tb_checkpoint = torch.load(\"checkpoints/resnet18_T-B_best.pth\", weights_only=False)\n",
        "model_TC.load_state_dict(tb_checkpoint[\"model_state_dict\"])\n",
        "print(f\"Loaded T-B checkpoint from epoch {tb_checkpoint['epoch']} \"\n",
        "      f\"(val F1: {tb_checkpoint['val_f1']:.4f})\\n\")\n",
        "\n",
        "apply_policy(model_TC, \"T-C\")\n",
        "model_TC = model_TC.to(device)\n",
        "\n",
        "model_TC, history_TC, best_TC = train_model(\n",
        "    model_TC, train_loader_TC, val_loader_TC, device,\n",
        "    num_epochs=HYPERPARAMS[\"T-C\"][\"num_epochs\"],\n",
        "    lr=HYPERPARAMS[\"T-C\"][\"lr\"],\n",
        "    weight_decay=HYPERPARAMS[\"T-C\"][\"weight_decay\"],\n",
        "    optimizer_name=HYPERPARAMS[\"T-C\"][\"optimizer\"],\n",
        "    experiment_name=\"T-C\"\n",
        ")\n",
        "\n",
        "torch.save(best_TC, \"checkpoints/resnet18_T-C_best.pth\")\n",
        "results_summary[\"T-C\"] = best_TC\n",
        "all_histories[\"T-C\"] = history_TC\n",
        "print(\"✓ Saved T-C checkpoint\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T22:22:38.751954Z",
          "iopub.execute_input": "2025-12-06T22:22:38.752522Z",
          "iopub.status.idle": "2025-12-06T22:22:38.818579Z",
          "shell.execute_reply.started": "2025-12-06T22:22:38.752498Z",
          "shell.execute_reply": "2025-12-06T22:22:38.81766Z"
        },
        "id": "_VEC_YZzIQTK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== S-A: TRAIN FROM SCRATCH =====\n",
        "print(\"=\" * 80)\n",
        "print(\"TRAINING: S-A (Train from Scratch)\")\n",
        "print(\"=\" * 80)\n",
        "print_params = HYPERPARAMS[\"S-A\"]\n",
        "print(f\"LR={print_params['lr']}, BatchSize={print_params['batch_size']}, \"\n",
        "      f\"Optimizer={print_params['optimizer']}, Epochs={print_params['num_epochs']}\\n\")\n",
        "\n",
        "train_loader_SA, val_loader_SA = create_dataloaders(\n",
        "    HYPERPARAMS[\"S-A\"][\"batch_size\"], train_idx, val_idx\n",
        ")\n",
        "\n",
        "model_SA = create_resnet18(num_classes=num_classes, pretrained=False)\n",
        "apply_policy(model_SA, \"S-A\")\n",
        "model_SA = model_SA.to(device)\n",
        "\n",
        "model_SA, history_SA, best_SA = train_model(\n",
        "    model_SA, train_loader_SA, val_loader_SA, device,\n",
        "    num_epochs=HYPERPARAMS[\"S-A\"][\"num_epochs\"],\n",
        "    lr=HYPERPARAMS[\"S-A\"][\"lr\"],\n",
        "    weight_decay=HYPERPARAMS[\"S-A\"][\"weight_decay\"],\n",
        "    optimizer_name=HYPERPARAMS[\"S-A\"][\"optimizer\"],\n",
        "    experiment_name=\"S-A\"\n",
        ")\n",
        "\n",
        "torch.save(best_SA, \"checkpoints/resnet18_S-A_best.pth\")\n",
        "results_summary[\"S-A\"] = best_SA\n",
        "all_histories[\"S-A\"] = history_SA\n",
        "print(\"✓ Saved S-A checkpoint\\n\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-12-06T22:21:53.201Z"
        },
        "id": "iBsjITIOIQTK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 7: ABLATION STUDY - VALIDATION SET COMPARISON\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ABLATION STUDY: Comparing All 4 Models on Validation Set\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "# Use standard dataloader for ablation\n",
        "pin = True if device.type == \"cuda\" else False\n",
        "val_loader_standard = DataLoader(\n",
        "    val_dataset, batch_size=64, shuffle=False,\n",
        "    num_workers=2, pin_memory=pin\n",
        ")\n",
        "\n",
        "ablation_results = {}\n",
        "\n",
        "for policy_name in [\"T-A\", \"T-B\", \"T-C\", \"S-A\"]:\n",
        "    checkpoint = results_summary[policy_name]\n",
        "    model = create_resnet18(num_classes=num_classes,\n",
        "                           pretrained=(policy_name != \"S-A\"))\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    model = model.to(device)\n",
        "\n",
        "    val_loss, val_acc, val_f1, preds, targets = evaluate(model, val_loader_standard, device)\n",
        "    cm = confusion_matrix(targets, preds)\n",
        "\n",
        "    ablation_results[policy_name] = {\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_acc\": val_acc,\n",
        "        \"val_f1\": val_f1,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "    print(f\"{policy_name:5s} | Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "best_policy = max(ablation_results, key=lambda x: ablation_results[x][\"val_f1\"])\n",
        "print(f\"✓ Best model: {best_policy} (F1: {ablation_results[best_policy]['val_f1']:.4f})\\n\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-12-06T22:21:53.201Z"
        },
        "id": "GKdhlssrIQTK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 8: PLOT TRAINING CURVES\n",
        "# ============================================================================\n",
        "\n",
        "def plot_training_curves(histories, experiment_names):\n",
        "    \"\"\"Plot training and validation curves.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle(\"Training Curves - Phase 1 Ablation Study\", fontsize=16, fontweight=\"bold\")\n",
        "\n",
        "    # Loss\n",
        "    ax = axes[0, 0]\n",
        "    for name, hist in zip(experiment_names, histories):\n",
        "        ax.plot(hist[\"train_loss\"], label=f\"{name} (train)\", marker=\"o\", alpha=0.7)\n",
        "        ax.plot(hist[\"val_loss\"], label=f\"{name} (val)\", marker=\"s\", alpha=0.7)\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Loss\")\n",
        "    ax.set_title(\"Loss vs Epoch\")\n",
        "    ax.legend(fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy\n",
        "    ax = axes[0, 1]\n",
        "    for name, hist in zip(experiment_names, histories):\n",
        "        ax.plot(hist[\"train_acc\"], label=f\"{name} (train)\", marker=\"o\", alpha=0.7)\n",
        "        ax.plot(hist[\"val_acc\"], label=f\"{name} (val)\", marker=\"s\", alpha=0.7)\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "    ax.set_title(\"Accuracy vs Epoch\")\n",
        "    ax.legend(fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # F1 Score\n",
        "    ax = axes[1, 0]\n",
        "    for name, hist in zip(experiment_names, histories):\n",
        "        ax.plot(hist[\"train_f1\"], label=f\"{name} (train)\", marker=\"o\", alpha=0.7)\n",
        "        ax.plot(hist[\"val_f1\"], label=f\"{name} (val)\", marker=\"s\", alpha=0.7)\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Macro-F1\")\n",
        "    ax.set_title(\"Macro-F1 vs Epoch\")\n",
        "    ax.legend(fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Summary table\n",
        "    ax = axes[1, 1]\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    table_data = []\n",
        "    for name in experiment_names:\n",
        "        hist = histories[experiment_names.index(name)]\n",
        "        table_data.append([\n",
        "            name,\n",
        "            f\"{hist['val_loss'][-1]:.4f}\",\n",
        "            f\"{hist['val_acc'][-1]:.4f}\",\n",
        "            f\"{hist['val_f1'][-1]:.4f}\",\n",
        "        ])\n",
        "\n",
        "    table = ax.table(\n",
        "        cellText=table_data,\n",
        "        colLabels=[\"Policy\", \"Val Loss\", \"Val Acc\", \"Val F1\"],\n",
        "        cellLoc=\"center\",\n",
        "        loc=\"center\",\n",
        "    )\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"✓ Training curves saved to training_curves.png\\n\")\n",
        "\n",
        "histories = [history_TA, history_TB, history_TC, history_SA]\n",
        "experiment_names = [\"T-A\", \"T-B\", \"T-C\", \"S-A\"]\n",
        "plot_training_curves(histories, experiment_names)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-12-06T22:21:53.201Z"
        },
        "id": "NztIhCGtIQTK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 9: TEST SET EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EVALUATING BEST MODEL ON ORIGINAL TEST SET (28 IMAGES)\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "def evaluate_test_set_with_filenames(model, test_loader, device, class_names):\n",
        "    \"\"\"Evaluate on flat test set and return predictions.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    all_filenames = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            images = batch[0].to(device)\n",
        "            filenames = batch[1]\n",
        "            true_labels_str = batch[2]\n",
        "\n",
        "            true_labels = torch.tensor([class_names.index(label) for label in true_labels_str]).to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_targets.append(true_labels.cpu())\n",
        "            all_filenames.extend(filenames)\n",
        "\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    accuracy = accuracy_score(all_targets, all_preds)\n",
        "    macro_f1 = f1_score(all_targets, all_preds, average=\"macro\", zero_division=0)\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "    return accuracy, macro_f1, cm, all_preds, all_targets, all_filenames\n",
        "\n",
        "# Create test dataloader\n",
        "pin = True if device.type == \"cuda\" else False\n",
        "test_loader_original = DataLoader(\n",
        "    test_dataset_original, batch_size=64, shuffle=False,\n",
        "    num_workers=2, pin_memory=pin\n",
        ")\n",
        "\n",
        "# Check which checkpoint files exist\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "existing_checkpoints = {}\n",
        "\n",
        "for policy in [\"T-A\", \"T-B\", \"T-C\", \"S-A\"]:\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"resnet18_{policy}_best.pth\")\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        existing_checkpoints[policy] = checkpoint_path\n",
        "        print(f\"✓ Found checkpoint: {policy}\")\n",
        "    else:\n",
        "        print(f\"✗ Missing checkpoint: {policy}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Determine best policy from existing checkpoints and ablation results\n",
        "available_policies = list(existing_checkpoints.keys())\n",
        "\n",
        "if available_policies:\n",
        "    # Find best among available\n",
        "    best_policy_available = None\n",
        "    best_f1_available = -1\n",
        "\n",
        "    for policy in available_policies:\n",
        "        if policy in ablation_results:\n",
        "            if ablation_results[policy][\"val_f1\"] > best_f1_available:\n",
        "                best_f1_available = ablation_results[policy][\"val_f1\"]\n",
        "                best_policy_available = policy\n",
        "\n",
        "    if best_policy_available is None:\n",
        "        best_policy_available = available_policies[0]\n",
        "\n",
        "    best_policy = best_policy_available\n",
        "    print(f\"Using {best_policy} as best model\\n\")\n",
        "else:\n",
        "    print(\"ERROR: No checkpoints found!\")\n",
        "    print(\"Available policies in ablation_results:\")\n",
        "    for policy in ablation_results:\n",
        "        print(f\"  {policy}: F1={ablation_results[policy]['val_f1']:.4f}\")\n",
        "    print(\"\\nPlease check if training completed successfully.\")\n",
        "    best_policy = max(ablation_results, key=lambda x: ablation_results[x][\"val_f1\"])\n",
        "    print(f\"Using {best_policy} from ablation results (but checkpoint may not exist)\\n\")\n",
        "\n",
        "# Load best model\n",
        "checkpoint_path = os.path.join(checkpoint_dir, f\"resnet18_{best_policy}_best.pth\")\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(f\"ERROR: Checkpoint {checkpoint_path} does not exist!\")\n",
        "    print(f\"Available files in {checkpoint_dir}:\")\n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        for f in os.listdir(checkpoint_dir):\n",
        "            print(f\"  - {f}\")\n",
        "    else:\n",
        "        print(f\"  Directory {checkpoint_dir} does not exist!\")\n",
        "\n",
        "    # Try to use any available checkpoint\n",
        "    if existing_checkpoints:\n",
        "        best_policy = list(existing_checkpoints.keys())[0]\n",
        "        checkpoint_path = existing_checkpoints[best_policy]\n",
        "        print(f\"\\nUsing fallback: {best_policy}\\n\")\n",
        "    else:\n",
        "        print(\"\\nCannot proceed without checkpoint!\")\n",
        "        print(\"Please ensure training completed successfully.\")\n",
        "        raise FileNotFoundError(f\"No checkpoint found for {best_policy}\")\n",
        "\n",
        "print(f\"Loading checkpoint: {checkpoint_path}\\n\")\n",
        "\n",
        "try:\n",
        "    best_checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading checkpoint: {e}\")\n",
        "    raise\n",
        "\n",
        "best_model = create_resnet18(num_classes=num_classes,\n",
        "                            pretrained=(best_policy != \"S-A\"))\n",
        "best_model.load_state_dict(best_checkpoint[\"model_state_dict\"])\n",
        "best_model = best_model.to(device)\n",
        "\n",
        "print(f\"Loaded {best_policy} model from epoch {best_checkpoint['epoch']}\")\n",
        "print(f\"(Val F1 at checkpoint: {best_checkpoint['val_f1']:.4f})\\n\")\n",
        "\n",
        "# Evaluate on original test set\n",
        "test_acc, test_f1, test_cm, test_preds, test_targets, test_fnames = \\\n",
        "    evaluate_test_set_with_filenames(best_model, test_loader_original, device,\n",
        "                                    full_train_dataset.classes)\n",
        "\n",
        "print(f\"Test Set Results ({best_policy}):\")\n",
        "print(f\"  Accuracy: {test_acc:.4f}\")\n",
        "print(f\"  Macro-F1: {test_f1:.4f}\")\n",
        "print(f\"  Images tested: {len(test_fnames)}\")\n",
        "print(f\"  Confusion Matrix shape: {test_cm.shape}\\n\")\n",
        "\n",
        "# Show individual predictions\n",
        "print(\"Individual Test Predictions:\")\n",
        "print(\"-\" * 70)\n",
        "for fname, pred, true in zip(test_fnames, test_preds, test_targets):\n",
        "    pred_class = full_train_dataset.classes[pred]\n",
        "    true_class = full_train_dataset.classes[true]\n",
        "    status = \"✓ CORRECT\" if pred == true else \"✗ WRONG\"\n",
        "    print(f\"{status:12s} | File: {fname:20s} | Predicted: {pred_class:10s} | True: {true_class:10s}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "correct_count = sum(1 for p, t in zip(test_preds, test_targets) if p == t)\n",
        "print(f\"Summary: {correct_count}/{len(test_fnames)} correct ({100*test_acc:.1f}%)\\n\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(14, 12))\n",
        "sns.heatmap(test_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=full_train_dataset.classes,\n",
        "            yticklabels=full_train_dataset.classes,\n",
        "            ax=ax, cbar_kws={\"label\": \"Count\"})\n",
        "ax.set_title(f\"Test Set Confusion Matrix - {best_policy} (28 Images)\\nAccuracy: {test_acc:.4f} | Macro-F1: {test_f1:.4f}\")\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel(\"True\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"confusion_matrix_{best_policy}_test.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"✓ Test confusion matrix saved\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "sfQ83tmnIQTK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 10: CUSTOM TEST SET EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CUSTOM TEST SET EVALUATION\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "# Check if we have the best model loaded\n",
        "if 'best_model' in locals() and 'best_policy' in locals():\n",
        "    try:\n",
        "        # Try custom test set from jadecw/try-custom2\n",
        "        CUSTOM_TEST_DIR = \"/kaggle/input/try-custom2/custom_test_set\"\n",
        "\n",
        "        if os.path.exists(CUSTOM_TEST_DIR):\n",
        "            print(f\"✓ Custom test set found at: {CUSTOM_TEST_DIR}\\n\")\n",
        "\n",
        "            custom_test_dataset = datasets.ImageFolder(\n",
        "                root=CUSTOM_TEST_DIR, transform=val_test_transform\n",
        "            )\n",
        "            custom_test_loader = DataLoader(\n",
        "                custom_test_dataset, batch_size=64, shuffle=False,\n",
        "                num_workers=2, pin_memory=pin\n",
        "            )\n",
        "\n",
        "            print(f\"Custom test set loaded:\")\n",
        "            print(f\"  Total images: {len(custom_test_dataset)}\")\n",
        "            print(f\"  Classes: {custom_test_dataset.classes}\\n\")\n",
        "\n",
        "            # Evaluate best model on custom test set\n",
        "            custom_loss, custom_acc, custom_f1, custom_preds, custom_targets = \\\n",
        "                evaluate(best_model, custom_test_loader, device)\n",
        "            custom_cm = confusion_matrix(custom_targets, custom_preds)\n",
        "\n",
        "            print(f\"Custom Test Set Results ({best_policy}):\")\n",
        "            print(f\"  Accuracy: {custom_acc:.4f}\")\n",
        "            print(f\"  Macro-F1: {custom_f1:.4f}\")\n",
        "            print(f\"  Images tested: {len(custom_test_dataset)}\\n\")\n",
        "\n",
        "            # Per-class results\n",
        "            print(\"Per-Class Results:\")\n",
        "            print(\"-\" * 70)\n",
        "            for i, class_name in enumerate(custom_test_dataset.classes):\n",
        "                class_mask = custom_targets == i\n",
        "                if class_mask.sum() > 0:\n",
        "                    class_correct = (custom_preds[class_mask] == custom_targets[class_mask]).sum()\n",
        "                    class_total = class_mask.sum()\n",
        "                    class_acc = class_correct / class_total\n",
        "                    status = \"✓\" if class_acc == 1.0 else \"✗\" if class_acc == 0.0 else \"~\"\n",
        "                    print(f\"{status} {class_name:15s}: {class_acc:.4f} ({int(class_correct)}/{int(class_total)})\")\n",
        "\n",
        "            print()\n",
        "\n",
        "            # Plot confusion matrix\n",
        "            fig, ax = plt.subplots(figsize=(12, 10))\n",
        "            sns.heatmap(custom_cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "                        xticklabels=custom_test_dataset.classes,\n",
        "                        yticklabels=custom_test_dataset.classes,\n",
        "                        ax=ax, cbar_kws={\"label\": \"Count\"})\n",
        "            ax.set_title(f\"Custom Test Confusion Matrix - {best_policy}\\nAccuracy: {custom_acc:.4f} | Macro-F1: {custom_f1:.4f}\")\n",
        "            ax.set_xlabel(\"Predicted\")\n",
        "            ax.set_ylabel(\"True\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"confusion_matrix_{best_policy}_custom.png\", dpi=150, bbox_inches=\"tight\")\n",
        "            plt.show()\n",
        "            print(\"✓ Custom test confusion matrix saved\\n\")\n",
        "\n",
        "            # Comparison with original test set\n",
        "            print(\"=\" * 70)\n",
        "            print(\"COMPARISON: Original vs Custom Test Set\")\n",
        "            print(\"=\" * 70)\n",
        "            print(f\"Original Test (28 images):  Acc={test_acc:.4f} | F1={test_f1:.4f}\")\n",
        "            print(f\"Custom Test ({len(custom_test_dataset)} images):   Acc={custom_acc:.4f} | F1={custom_f1:.4f}\")\n",
        "\n",
        "            acc_diff = custom_acc - test_acc\n",
        "            f1_diff = custom_f1 - test_f1\n",
        "            print(f\"\\nDifference (Custom - Original):\")\n",
        "            print(f\"  Accuracy: {acc_diff:+.4f}\")\n",
        "            print(f\"  Macro-F1: {f1_diff:+.4f}\")\n",
        "\n",
        "            if acc_diff > 0 and f1_diff > 0:\n",
        "                print(f\"  ✓ Custom test performs BETTER than original\")\n",
        "            elif acc_diff < 0 or f1_diff < 0:\n",
        "                print(f\"  ⚠️  Custom test performs WORSE than original (may indicate overfitting)\")\n",
        "            else:\n",
        "                print(f\"  ~ Similar performance\")\n",
        "            print()\n",
        "\n",
        "        else:\n",
        "            print(f\"⚠️  Custom test set not found at: {CUSTOM_TEST_DIR}\")\n",
        "            print(\"Tried path: /kaggle/input/jadecw-try-custom2/custom_test_set\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Error loading custom test set: {e}\\n\")\n",
        "\n",
        "else:\n",
        "    print(\"⚠️  Best model not loaded - skipping custom test evaluation\\n\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZYV5Zw5qIQTK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 11: FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FINAL SUMMARY - PHASE 1 COMPLETE\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "# Check if we have results\n",
        "if 'ablation_results' in locals() and ablation_results:\n",
        "\n",
        "    # Summary table\n",
        "    print(\"Ablation Study Results (Validation Set):\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'Policy':<8} {'Val Loss':<12} {'Val Acc':<12} {'Val F1':<12}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for policy_name in [\"T-A\", \"T-B\", \"T-C\", \"S-A\"]:\n",
        "        if policy_name in ablation_results:\n",
        "            result = ablation_results[policy_name]\n",
        "            print(f\"{policy_name:<8} {result['val_loss']:<12.4f} \"\n",
        "                  f\"{result['val_acc']:<12.4f} {result['val_f1']:<12.4f}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    # Best model summary\n",
        "    best_val_result = ablation_results[best_policy]\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"BEST MODEL: {best_policy}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"  Val Loss: {best_val_result['val_loss']:.4f}\")\n",
        "    print(f\"  Val Accuracy: {best_val_result['val_acc']:.4f}\")\n",
        "    print(f\"  Val Macro-F1: {best_val_result['val_f1']:.4f}\\n\")\n",
        "\n",
        "    print(\"Test Set Performance:\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"  Original Test (28 images):\")\n",
        "    print(f\"    - Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"    - Macro-F1: {test_f1:.4f}\\n\")\n",
        "\n",
        "else:\n",
        "    print(\"⚠️  No training results available\\n\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"✓ PHASE 1 COMPLETE - All Models Trained & Evaluated!\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "PsrIjN4qIQTL"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}